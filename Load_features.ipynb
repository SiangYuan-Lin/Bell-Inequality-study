{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f0d30663-37b2-4131-a582-a05edb6230e4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../Updated background features/bkg_sample_features/LpNu/LpNu_5.csv\n",
      "../Updated background features/bkg_sample_features/LpNu/LpNu_1.csv\n",
      "../Updated background features/bkg_sample_features/LpNu/LpNu_9.csv\n",
      "../Updated background features/bkg_sample_features/LpNu/LpNu_4.csv\n",
      "../Updated background features/bkg_sample_features/LpNu/LpNu_2.csv\n",
      "../Updated background features/bkg_sample_features/LpNu/LpNu_7.csv\n",
      "../Updated background features/bkg_sample_features/LpNu/LpNu_0.csv\n",
      "../Updated background features/bkg_sample_features/LpNu/LpNu_8.csv\n",
      "../Updated background features/bkg_sample_features/LpNu/LpNu_6.csv\n",
      "../Updated background features/bkg_sample_features/LpNu/LpNu_3.csv\n",
      "../Updated background features/bkg_sample_features/WmBoson/WmBoson_2.csv\n",
      "../Updated background features/bkg_sample_features/WmBoson/WmBoson_6.csv\n",
      "../Updated background features/bkg_sample_features/WmBoson/WmBoson_4.csv\n",
      "../Updated background features/bkg_sample_features/WmBoson/WmBoson_1.csv\n",
      "../Updated background features/bkg_sample_features/WmBoson/WmBoson_5.csv\n",
      "../Updated background features/bkg_sample_features/WmBoson/WmBoson_7.csv\n",
      "../Updated background features/bkg_sample_features/WmBoson/WmBoson_3.csv\n",
      "../Updated background features/bkg_sample_features/WmBoson/WmBoson_8.csv\n",
      "../Updated background features/bkg_sample_features/WmBoson/WmBoson_0.csv\n",
      "../Updated background features/bkg_sample_features/WmBoson/WmBoson_9.csv\n",
      "../Updated background features/bkg_sample_features/LmNu/LmNu_4.csv\n",
      "../Updated background features/bkg_sample_features/LmNu/LmNu_0.csv\n",
      "../Updated background features/bkg_sample_features/LmNu/LmNu_1.csv\n",
      "../Updated background features/bkg_sample_features/LmNu/LmNu_7.csv\n",
      "../Updated background features/bkg_sample_features/LmNu/LmNu_8.csv\n",
      "../Updated background features/bkg_sample_features/LmNu/LmNu_6.csv\n",
      "../Updated background features/bkg_sample_features/LmNu/LmNu_5.csv\n",
      "../Updated background features/bkg_sample_features/LmNu/LmNu_9.csv\n",
      "../Updated background features/bkg_sample_features/LmNu/LmNu_2.csv\n",
      "../Updated background features/bkg_sample_features/LmNu/LmNu_3.csv\n",
      "../Updated background features/bkg_sample_features/LeadLepton/LeadLepton_2.csv\n",
      "../Updated background features/bkg_sample_features/LeadLepton/LeadLepton_0.csv\n",
      "../Updated background features/bkg_sample_features/LeadLepton/LeadLepton_1.csv\n",
      "../Updated background features/bkg_sample_features/LeadLepton/LeadLepton_5.csv\n",
      "../Updated background features/bkg_sample_features/LeadLepton/LeadLepton_3.csv\n",
      "../Updated background features/bkg_sample_features/LeadLepton/LeadLepton_6.csv\n",
      "../Updated background features/bkg_sample_features/LeadLepton/LeadLepton_4.csv\n",
      "../Updated background features/bkg_sample_features/LeadLepton/LeadLepton_7.csv\n",
      "../Updated background features/bkg_sample_features/LeadLepton/LeadLepton_9.csv\n",
      "../Updated background features/bkg_sample_features/LeadLepton/LeadLepton_8.csv\n",
      "../Updated background features/bkg_sample_features/xi_xyz/xi_p_m_xyz_1.csv\n",
      "../Updated background features/bkg_sample_features/xi_xyz/xi_p_m_xyz_6.csv\n",
      "../Updated background features/bkg_sample_features/xi_xyz/xi_p_m_xyz_0.csv\n",
      "../Updated background features/bkg_sample_features/xi_xyz/xi_p_m_xyz_8.csv\n",
      "../Updated background features/bkg_sample_features/xi_xyz/xi_p_m_xyz_5.csv\n",
      "../Updated background features/bkg_sample_features/xi_xyz/xi_p_m_xyz_7.csv\n",
      "../Updated background features/bkg_sample_features/xi_xyz/xi_p_m_xyz_2.csv\n",
      "../Updated background features/bkg_sample_features/xi_xyz/xi_p_m_xyz_4.csv\n",
      "../Updated background features/bkg_sample_features/xi_xyz/xi_p_m_xyz_3.csv\n",
      "../Updated background features/bkg_sample_features/xi_xyz/xi_p_m_xyz_9.csv\n",
      "../Updated background features/bkg_sample_features/LeadingPair/LeadingPair_9.csv\n",
      "../Updated background features/bkg_sample_features/LeadingPair/LeadingPair_8.csv\n",
      "../Updated background features/bkg_sample_features/LeadingPair/LeadingPair_6.csv\n",
      "../Updated background features/bkg_sample_features/LeadingPair/LeadingPair_1.csv\n",
      "../Updated background features/bkg_sample_features/LeadingPair/LeadingPair_4.csv\n",
      "../Updated background features/bkg_sample_features/LeadingPair/LeadingPair_3.csv\n",
      "../Updated background features/bkg_sample_features/LeadingPair/LeadingPair_2.csv\n",
      "../Updated background features/bkg_sample_features/LeadingPair/LeadingPair_0.csv\n",
      "../Updated background features/bkg_sample_features/LeadingPair/LeadingPair_7.csv\n",
      "../Updated background features/bkg_sample_features/LeadingPair/LeadingPair_5.csv\n",
      "../Updated background features/bkg_sample_features/subLeadLepton/subLeadLepton_3.csv\n",
      "../Updated background features/bkg_sample_features/subLeadLepton/subLeadLepton_2.csv\n",
      "../Updated background features/bkg_sample_features/subLeadLepton/subLeadLepton_5.csv\n",
      "../Updated background features/bkg_sample_features/subLeadLepton/subLeadLepton_4.csv\n",
      "../Updated background features/bkg_sample_features/subLeadLepton/subLeadLepton_8.csv\n",
      "../Updated background features/bkg_sample_features/subLeadLepton/subLeadLepton_6.csv\n",
      "../Updated background features/bkg_sample_features/subLeadLepton/subLeadLepton_7.csv\n",
      "../Updated background features/bkg_sample_features/subLeadLepton/subLeadLepton_0.csv\n",
      "../Updated background features/bkg_sample_features/subLeadLepton/subLeadLepton_1.csv\n",
      "../Updated background features/bkg_sample_features/subLeadLepton/subLeadLepton_9.csv\n",
      "../Updated background features/bkg_sample_features/LeptonP/LeptonP_1.csv\n",
      "../Updated background features/bkg_sample_features/LeptonP/LeptonP_8.csv\n",
      "../Updated background features/bkg_sample_features/LeptonP/LeptonP_9.csv\n",
      "../Updated background features/bkg_sample_features/LeptonP/LeptonP_2.csv\n",
      "../Updated background features/bkg_sample_features/LeptonP/LeptonP_5.csv\n",
      "../Updated background features/bkg_sample_features/LeptonP/LeptonP_7.csv\n",
      "../Updated background features/bkg_sample_features/LeptonP/LeptonP_0.csv\n",
      "../Updated background features/bkg_sample_features/LeptonP/LeptonP_3.csv\n",
      "../Updated background features/bkg_sample_features/LeptonP/LeptonP_6.csv\n",
      "../Updated background features/bkg_sample_features/LeptonP/LeptonP_4.csv\n",
      "../Updated background features/bkg_sample_features/MET/MET_4.csv\n",
      "../Updated background features/bkg_sample_features/MET/MET_8.csv\n",
      "../Updated background features/bkg_sample_features/MET/MET_1.csv\n",
      "../Updated background features/bkg_sample_features/MET/MET_5.csv\n",
      "../Updated background features/bkg_sample_features/MET/MET_3.csv\n",
      "../Updated background features/bkg_sample_features/MET/MET_6.csv\n",
      "../Updated background features/bkg_sample_features/MET/MET_2.csv\n",
      "../Updated background features/bkg_sample_features/MET/MET_7.csv\n",
      "../Updated background features/bkg_sample_features/MET/MET_9.csv\n",
      "../Updated background features/bkg_sample_features/MET/MET_0.csv\n",
      "../Updated background features/bkg_sample_features/Higgs/Higgs_0.csv\n",
      "../Updated background features/bkg_sample_features/Higgs/Higgs_3.csv\n",
      "../Updated background features/bkg_sample_features/Higgs/Higgs_6.csv\n",
      "../Updated background features/bkg_sample_features/Higgs/Higgs_8.csv\n",
      "../Updated background features/bkg_sample_features/Higgs/Higgs_5.csv\n",
      "../Updated background features/bkg_sample_features/Higgs/Higgs_1.csv\n",
      "../Updated background features/bkg_sample_features/Higgs/Higgs_7.csv\n",
      "../Updated background features/bkg_sample_features/Higgs/Higgs_4.csv\n",
      "../Updated background features/bkg_sample_features/Higgs/Higgs_9.csv\n",
      "../Updated background features/bkg_sample_features/Higgs/Higgs_2.csv\n",
      "../Updated background features/bkg_sample_features/LeptonM/LeptonM_4.csv\n",
      "../Updated background features/bkg_sample_features/LeptonM/LeptonM_2.csv\n",
      "../Updated background features/bkg_sample_features/LeptonM/LeptonM_1.csv\n",
      "../Updated background features/bkg_sample_features/LeptonM/LeptonM_6.csv\n",
      "../Updated background features/bkg_sample_features/LeptonM/LeptonM_0.csv\n",
      "../Updated background features/bkg_sample_features/LeptonM/LeptonM_3.csv\n",
      "../Updated background features/bkg_sample_features/LeptonM/LeptonM_7.csv\n",
      "../Updated background features/bkg_sample_features/LeptonM/LeptonM_9.csv\n",
      "../Updated background features/bkg_sample_features/LeptonM/LeptonM_8.csv\n",
      "../Updated background features/bkg_sample_features/LeptonM/LeptonM_5.csv\n",
      "../Updated background features/bkg_sample_features/WpBoson/WpBoson_9.csv\n",
      "../Updated background features/bkg_sample_features/WpBoson/WpBoson_3.csv\n",
      "../Updated background features/bkg_sample_features/WpBoson/WpBoson_5.csv\n",
      "../Updated background features/bkg_sample_features/WpBoson/WpBoson_6.csv\n",
      "../Updated background features/bkg_sample_features/WpBoson/WpBoson_8.csv\n",
      "../Updated background features/bkg_sample_features/WpBoson/WpBoson_4.csv\n",
      "../Updated background features/bkg_sample_features/WpBoson/WpBoson_1.csv\n",
      "../Updated background features/bkg_sample_features/WpBoson/WpBoson_7.csv\n",
      "../Updated background features/bkg_sample_features/WpBoson/WpBoson_0.csv\n",
      "../Updated background features/bkg_sample_features/WpBoson/WpBoson_2.csv\n",
      "../Updated background features/bkg_sample_features/B_xyz/Bxy_yz_zx_4.csv\n",
      "../Updated background features/bkg_sample_features/B_xyz/Bxy_yz_zx_8.csv\n",
      "../Updated background features/bkg_sample_features/B_xyz/Bxy_yz_zx_5.csv\n",
      "../Updated background features/bkg_sample_features/B_xyz/Bxy_yz_zx_1.csv\n",
      "../Updated background features/bkg_sample_features/B_xyz/Bxy_yz_zx_0.csv\n",
      "../Updated background features/bkg_sample_features/B_xyz/Bxy_yz_zx_2.csv\n",
      "../Updated background features/bkg_sample_features/B_xyz/Bxy_yz_zx_7.csv\n",
      "../Updated background features/bkg_sample_features/B_xyz/Bxy_yz_zx_9.csv\n",
      "../Updated background features/bkg_sample_features/B_xyz/Bxy_yz_zx_6.csv\n",
      "../Updated background features/bkg_sample_features/B_xyz/Bxy_yz_zx_3.csv\n",
      "../Updated background features/bkg_sample_features/diLepton/diLepton_7.csv\n",
      "../Updated background features/bkg_sample_features/diLepton/diLepton_0.csv\n",
      "../Updated background features/bkg_sample_features/diLepton/diLepton_6.csv\n",
      "../Updated background features/bkg_sample_features/diLepton/diLepton_1.csv\n",
      "../Updated background features/bkg_sample_features/diLepton/diLepton_4.csv\n",
      "../Updated background features/bkg_sample_features/diLepton/diLepton_2.csv\n",
      "../Updated background features/bkg_sample_features/diLepton/diLepton_3.csv\n",
      "../Updated background features/bkg_sample_features/diLepton/diLepton_9.csv\n",
      "../Updated background features/bkg_sample_features/diLepton/diLepton_5.csv\n",
      "../Updated background features/bkg_sample_features/diLepton/diLepton_8.csv\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.patches import Rectangle\n",
    "import seaborn as sns\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "# filepath = './Updated signal features/'\n",
    "filepath = '../Updated background features/bkg_sample_features/'\n",
    "import os\n",
    "for dirname, _, filenames in os.walk(filepath):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cc76605a-4304-42e3-a897-2108a6745513",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "Total Events: 22417648\n",
      "Removed Events: 17487616 (78.0083%)\n",
      "Valid Events: 4930032 (21.9917%)\n",
      "CPU times: user 28.1 s, sys: 3.56 s, total: 31.7 s\n",
      "Wall time: 31.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "Higgs_E = np.array([])\n",
    "for i in range(10):\n",
    "    print(i)\n",
    "    E = np.genfromtxt(filepath+f'Higgs/Higgs_{i}.csv',usecols=0,delimiter=',')\n",
    "    Higgs_E = np.concatenate([Higgs_E,E])\n",
    "removed_rows = np.where(Higgs_E == -99999, False, True)\n",
    "_, count = np.unique(removed_rows,return_counts=True)\n",
    "print(f'Total Events: {len(removed_rows)}\\n'+\n",
    "      f'Removed Events: {count[0]} ({\"%.4f\"% (100*count[0]/len(removed_rows))}%)\\n'+\n",
    "      f'Valid Events: {count[1]} ({\"%.4f\"% (100*count[1]/len(removed_rows))}%)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c4043ab9-d4c7-4083-a97b-13683d1f7d1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "Total Events: 24306087\n",
      "Removed Events: 18960017 (78.0052%)\n",
      "Valid Events: 5346070 (21.9948%)\n",
      "CPU times: user 30.4 s, sys: 2.75 s, total: 33.2 s\n",
      "Wall time: 33.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "lp_E = np.array([])\n",
    "for i in range(10):\n",
    "    print(i)\n",
    "    E = np.genfromtxt(filepath+f'WmBoson/WmBoson_{i}.csv',usecols=0,delimiter=',')\n",
    "    lp_E = np.concatenate([lp_E,E])\n",
    "removed_rows = np.where(lp_E == -99999, False, True)\n",
    "_, count = np.unique(removed_rows,return_counts=True)\n",
    "print(f'Total Events: {len(removed_rows)}\\n'+\n",
    "      f'Removed Events: {count[0]} ({\"%.4f\"% (100*count[0]/len(removed_rows))}%)\\n'+\n",
    "      f'Valid Events: {count[1]} ({\"%.4f\"% (100*count[1]/len(removed_rows))}%)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e92a81a8-63bc-4fee-9b8a-40568eab0064",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../Updated background features/bkg_sample_features/Higgs/Higgs_0.csv 2500000\n",
      "../Updated background features/bkg_sample_features/LeadLepton/LeadLepton_0.csv 2403303\n",
      "../Updated background features/bkg_sample_features/subLeadLepton/subLeadLepton_0.csv 2375049\n",
      "../Updated background features/bkg_sample_features/Higgs/Higgs_1.csv 2495901\n",
      "../Updated background features/bkg_sample_features/LeadLepton/LeadLepton_1.csv 2500000\n",
      "../Updated background features/bkg_sample_features/subLeadLepton/subLeadLepton_1.csv 2324997\n",
      "../Updated background features/bkg_sample_features/Higgs/Higgs_2.csv 2201162\n",
      "../Updated background features/bkg_sample_features/LeadLepton/LeadLepton_2.csv 2285165\n",
      "../Updated background features/bkg_sample_features/subLeadLepton/subLeadLepton_2.csv 1834198\n",
      "../Updated background features/bkg_sample_features/Higgs/Higgs_3.csv 2477258\n",
      "../Updated background features/bkg_sample_features/LeadLepton/LeadLepton_3.csv 2445278\n",
      "../Updated background features/bkg_sample_features/subLeadLepton/subLeadLepton_3.csv 2302639\n",
      "../Updated background features/bkg_sample_features/Higgs/Higgs_4.csv 2089884\n",
      "../Updated background features/bkg_sample_features/LeadLepton/LeadLepton_4.csv 2370300\n",
      "../Updated background features/bkg_sample_features/subLeadLepton/subLeadLepton_4.csv 2148886\n",
      "../Updated background features/bkg_sample_features/Higgs/Higgs_5.csv 2318990\n",
      "../Updated background features/bkg_sample_features/LeadLepton/LeadLepton_5.csv 2256223\n",
      "../Updated background features/bkg_sample_features/subLeadLepton/subLeadLepton_5.csv 2456967\n",
      "../Updated background features/bkg_sample_features/Higgs/Higgs_6.csv 2029979\n",
      "../Updated background features/bkg_sample_features/LeadLepton/LeadLepton_6.csv 2500000\n",
      "../Updated background features/bkg_sample_features/subLeadLepton/subLeadLepton_6.csv 2292139\n",
      "../Updated background features/bkg_sample_features/Higgs/Higgs_7.csv 1811633\n",
      "../Updated background features/bkg_sample_features/LeadLepton/LeadLepton_7.csv 2284787\n",
      "../Updated background features/bkg_sample_features/subLeadLepton/subLeadLepton_7.csv 2292106\n",
      "../Updated background features/bkg_sample_features/Higgs/Higgs_8.csv 2392496\n",
      "../Updated background features/bkg_sample_features/LeadLepton/LeadLepton_8.csv 913893\n",
      "../Updated background features/bkg_sample_features/subLeadLepton/subLeadLepton_8.csv 2500000\n",
      "../Updated background features/bkg_sample_features/Higgs/Higgs_9.csv 2100345\n",
      "../Updated background features/bkg_sample_features/LeadLepton/LeadLepton_9.csv 2400000\n",
      "../Updated background features/bkg_sample_features/subLeadLepton/subLeadLepton_9.csv 2400000\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    Higgs_E = np.genfromtxt(filepath+f'Higgs/Higgs_{i}.csv',usecols=0,delimiter=',')\n",
    "    ll_E = np.genfromtxt(filepath+f'LeadLepton/LeadLepton_{i}.csv',usecols=0,delimiter=',')\n",
    "    sl_E = np.genfromtxt(filepath+f'subLeadLepton/subLeadLepton_{i}.csv',usecols=0,delimiter=',')\n",
    "    print(filepath+f'Higgs/Higgs_{i}.csv',len(Higgs_E))\n",
    "    print(filepath+f'LeadLepton/LeadLepton_{i}.csv',len(ll_E))\n",
    "    print(filepath+f'subLeadLepton/subLeadLepton_{i}.csv',len(sl_E))\n",
    "del(Higgs_E,ll_E,sl_E)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e01f155f-852a-478a-82cf-d354c99b70ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "#particle->e(),particle->px(),particle->py(),particle->pz(),\n",
    "#particle->m(),particle->pt(),particle->eta(),particle->phi(),particle->rapidity()\n",
    "particle_labels = ['E', 'px', 'py', 'pz', 'm', 'pT', 'eta', 'phi', 'y']\n",
    "LeptonP = pd.DataFrame(columns=particle_labels) #1\n",
    "LeptonM = pd.DataFrame(columns=particle_labels) #2\n",
    "diLepton = pd.DataFrame(columns=particle_labels) #3\n",
    "LeadLepton = pd.DataFrame(columns=particle_labels) #4\n",
    "subLeadLepton = pd.DataFrame(columns=particle_labels) #5\n",
    "NeutrinoP = pd.DataFrame(columns=particle_labels) #6\n",
    "NeutrinoM = pd.DataFrame(columns=particle_labels) #7\n",
    "WpBoson = pd.DataFrame(columns=particle_labels) #8\n",
    "WmBoson = pd.DataFrame(columns=particle_labels) #9\n",
    "Higgs = pd.DataFrame(columns=particle_labels) #10\n",
    "MET_labels = ['pT', 'px', 'py,', 'phi']\n",
    "MET = pd.DataFrame(columns=MET_labels)  #11\n",
    "xi_labels = ['xi_p_x', 'xi_p_y', 'xi_p_z','xi_m_x', 'xi_m_y', 'xi_m_z']\n",
    "xi_p_m_xyz = pd.DataFrame(columns=xi_labels) #12\n",
    "CGLMP_labels = ['B_xy', 'B_yz', 'B_zx']\n",
    "B_xy_yz_zx = pd.DataFrame(columns=CGLMP_labels) #13\n",
    "\n",
    "labels = [particle_labels, MET_labels, xi_labels, CGLMP_labels]\n",
    "filenames = ['LeptonP', 'LeptonM', 'diLepton', 'LeadLepton', 'subLeadLepton', 'LpNu', 'LmNu', 'WpBoson', 'WmBoson', 'Higgs', 'MET', 'xi_p_m_xyz', 'Bxy_yz_zx']\n",
    "data =      [ LeptonP ,  LeptonM ,  diLepton ,  LeadLepton ,  subLeadLepton,NeutrinoP,NeutrinoM,WpBoson,  WmBoson ,  Higgs ,  MET ,  xi_p_m_xyz , B_xy_yz_zx ]\n",
    "\n",
    "for i, j in enumerate(filenames):\n",
    "    for k in range(10):# 0,1,2,3,4,5,6\n",
    "        label = labels[0] if i < 10 else labels[i-9]\n",
    "        df = pd.read_csv(filepath+f'{j}/{j}_{k}.csv',\n",
    "                         index_col=False,\n",
    "                         header=None,\n",
    "                         names=label,\n",
    "                         usecols=[n for n in range(len(label))])\n",
    "        data[i] = pd.concat([data[i],df], ignore_index=True)\n",
    "    #print(i,j,k)\n",
    "    data[i] = data[i].loc[removed_rows,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7cf78b9c-b04f-4e15-af63-1285f62d2963",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 LeptonP (2928862, 9)\n",
      "1 LeptonM (2928862, 9)\n",
      "2 diLepton (2928862, 9)\n",
      "3 LeadLepton (2928862, 9)\n",
      "4 subLeadLepton (2928862, 9)\n",
      "5 LpNu (2928862, 9)\n",
      "6 LmNu (2928862, 9)\n",
      "7 WpBoson (2928862, 9)\n",
      "8 WmBoson (2928862, 9)\n",
      "9 Higgs (2928862, 9)\n",
      "10 MET (2928862, 4)\n",
      "11 xi_p_m_xyz (2928862, 6)\n",
      "12 Bxy_yz_zx (2928862, 3)\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(filenames)):\n",
    "    print(i,filenames[i],data[i].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f683ac09-0cbd-4b35-9c52-5c66b3fa1a42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 9.14 s, sys: 103 ms, total: 9.24 s\n",
      "Wall time: 9.24 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# CGLMP_labels = ['B_xy', 'B_yz', 'B_zx']\n",
    "# xi_labels = ['xi_p_x', 'xi_p_y', 'xi_p_z','xi_m_x', 'xi_m_y', 'xi_m_z']\n",
    "# MET_labels = ['pT', 'px', 'py,', 'phi']\n",
    "dir = 'npz files/'\n",
    "np.savez_compressed(filepath + dir + 'CGLMP', Bxy = data[12][CGLMP_labels[0]].to_numpy(),\n",
    "                                              Byz = data[12][CGLMP_labels[1]].to_numpy(),\n",
    "                                              Bzx = data[12][CGLMP_labels[2]].to_numpy())\n",
    "\n",
    "np.savez_compressed(filepath + dir + 'xi_xyz', xi_p_x = data[11][xi_labels[0]].to_numpy(),\n",
    "                                               xi_p_y = data[11][xi_labels[1]].to_numpy(),\n",
    "                                               xi_p_z = data[11][xi_labels[2]].to_numpy(),\n",
    "                                               xi_m_x = data[11][xi_labels[3]].to_numpy(),\n",
    "                                               xi_m_y = data[11][xi_labels[4]].to_numpy(),\n",
    "                                               xi_m_z = data[11][xi_labels[5]].to_numpy())\n",
    "np.savez_compressed(filepath + dir + 'MET', pt  = data[10][MET_labels[0]].to_numpy(),\n",
    "                                            px  = data[10][MET_labels[1]].to_numpy(),\n",
    "                                            py  = data[10][MET_labels[2]].to_numpy(),\n",
    "                                            phi = data[10][MET_labels[3]].to_numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "51e333ca-d27d-4993-b1e5-fc198d049071",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./Updated signal features/npz files\n"
     ]
    }
   ],
   "source": [
    "print(filepath+dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "08794f99-b3fe-47e1-93a3-4a1529c6db7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 LeptonP\n",
      "1 LeptonM\n",
      "2 diLepton\n",
      "3 LeadLepton\n",
      "4 subLeadLepton\n",
      "5 LpNu\n",
      "6 LmNu\n",
      "7 WpBoson\n",
      "8 WmBoson\n",
      "9 Higgs\n"
     ]
    }
   ],
   "source": [
    "# particle_labels = ['E', 'px', 'py', 'pz', 'm', 'pT', 'eta', 'phi', 'y']\n",
    "%%time\n",
    "for i, j in enumerate(filenames[0:-3]):\n",
    "    print(i,j)\n",
    "    np.savez_compressed(filepath + dir + j, E   = data[i][particle_labels[0]].to_numpy(),\n",
    "                                            px  = data[i][particle_labels[1]].to_numpy(),\n",
    "                                            py  = data[i][particle_labels[2]].to_numpy(),\n",
    "                                            pz  = data[i][particle_labels[3]].to_numpy(),\n",
    "                                            m   = data[i][particle_labels[4]].to_numpy(),\n",
    "                                            pt  = data[i][particle_labels[5]].to_numpy(),\n",
    "                                            eta = data[i][particle_labels[6]].to_numpy(),\n",
    "                                            phi = data[i][particle_labels[7]].to_numpy(),\n",
    "                                            y   = data[i][particle_labels[8]].to_numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "889ca489-68fd-419f-9585-87a7ccc31ca6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#a = np.arange(len(lp_phi))\n",
    "#b = np.arange(len(lm_phi))\n",
    "lp_phi = np.where(lp_phi == -99999, True, False)\n",
    "lm_phi = np.where(lm_phi == -99999, True, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "698dc9c9-d2a3-47bd-9d95-ba79b11638ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True False 792530\n"
     ]
    }
   ],
   "source": [
    "i=0\n",
    "a=1\n",
    "while a != 0:\n",
    "    a = 1 if lp_phi[i] == lm_phi[i] else 0\n",
    "    i+=1\n",
    "print(lp_phi[i -1],lm_phi[i- 1], i-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b529674a-b298-427c-b54c-93ea72219e08",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
